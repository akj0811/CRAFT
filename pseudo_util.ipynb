{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "References: \n",
    "https://opencv-python-tutroals.readthedocs.io/en/latest/py_tutorials/py_imgproc/py_watershed/py_watershed.html\n",
    "\"\"\"\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "from affinity_util import *\n",
    "\n",
    "\"Values taken from original author's implementation\"\n",
    "NORMALIZE_MEAN = np.array([0.485, 0.456, 0.406], dtype=np.float32) * 255.0\n",
    "NORMALIZE_VARIANCE = np.array([0.229, 0.224, 0.225], dtype=np.float32) * 255.0\n",
    "\n",
    "def watershed(inp):\n",
    "    gray = inp.copy()\n",
    "    img = cv2.cvtColor(gray, cv2.COLOR_GRAY2BGR)\n",
    "    _ret, thresh = cv2.threshold(gray,0,255,cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n",
    "    \n",
    "    # noise removal\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    # sure background area\n",
    "    sure_bg = cv2.dilate(opening, kernel, iterations=3)\n",
    "\n",
    "    # Finding sure foreground area\n",
    "    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)\n",
    "    _ret, sure_fg = cv2.threshold(dist_transform, 0.2 * dist_transform.max(), 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Finding unknown region\n",
    "    sure_fg = np.uint8(sure_fg)\n",
    "    unknown = cv2.subtract(sure_bg,sure_fg)\n",
    "    \n",
    "    # Marker labelling\n",
    "    ret, markers = cv2.connectedComponents(sure_fg)\n",
    "\n",
    "    # Add one to all labels so that sure background is not 0, but 1\n",
    "    markers = markers+1\n",
    "\n",
    "    # Now, mark the region of unknown with zero\n",
    "    markers[unknown==255] = 0\n",
    "    markers = cv2.watershed(img, markers)\n",
    "    \n",
    "    return markers\n",
    "\n",
    "def find_char_box(markers):\n",
    "    boxes = []\n",
    "    marker_count = np.max(markers)\n",
    "    for i in range(2,marker_count+1):\n",
    "        cnt = np.swapaxes(np.array(np.where(markers == i)), axis1=0, axis2=1)[:, ::-1]\n",
    "        rect = cv2.minAreaRect(cnt)\n",
    "        box = cv2.boxPoints(rect)\n",
    "        box = np.int0(box)\n",
    "        boxes.append(box)\n",
    "    return boxes\n",
    "\n",
    "def dist(p1, p2):\n",
    "    return math.sqrt(math.pow((p2[0] - p1[0]), 2) + math.pow((p2[1] - p1[1]), 2))\n",
    "\n",
    "def crop_image(src, points, dst_height=None):\n",
    "    \"\"\"\n",
    "    Crop image with box points.\n",
    "    src - Input image\n",
    "    points - coordinates of box\n",
    "    dst_height - optional parameter for fixed height of box \n",
    "    (note that this is not same as variable h but actual height of character)\n",
    "    \"\"\"\n",
    "    src_image = src.copy()\n",
    "    src_points = np.float32(points)\n",
    "    w = round((dist(points[0], points[1]) + dist(points[2], points[3])) / 2)\n",
    "    h = round((dist(points[1], points[2]) + dist(points[3], points[0])) / 2)\n",
    "    \n",
    "    #set to fixed height\n",
    "    if dst_height is not None:\n",
    "        ratio = dst_height / min(w, h)\n",
    "        w = int(w * ratio)\n",
    "        h = int(h * ratio)\n",
    "        \n",
    "    #get cropped image\n",
    "    crop_points = np.float32([[0, 0], [w, 0], [w, h], [0, h]])\n",
    "    perspective_mat = cv2.getPerspectiveTransform(src=src_points, dst=crop_points)\n",
    "    dst = cv2.warpPerspective(src_image, perspective_mat, (w, h), borderValue=0, borderMode=cv2.BORDER_CONSTANT)\n",
    "    return dst, src_points, crop_points\n",
    "\n",
    "def un_warping(box, src_points, crop_points):\n",
    "    \"\"\"\n",
    "    Unwarp the character bounding boxes.\n",
    "    box - The character bounding box.\n",
    "    src_points - Points before crop.\n",
    "    crop_points - Points after crop.\n",
    "    \"\"\"\n",
    "    perspective_mat = cv2.getPerspectiveTransform(src=crop_points, dst=src_points)\n",
    "    new_box = list()\n",
    "    for x, y in box:\n",
    "        new_x = int(np.dot(perspective_mat[0], [x,y,1]) /np.dot(perspective_mat[2], [x,y,1]))\n",
    "        new_y = int(np.dot(perspective_mat[1], [x,y,1]) /np.dot(perspective_mat[2], [x,y,1]))\n",
    "        new_box.append([new_x, new_y])\n",
    "    return new_box\n",
    "\n",
    "def divide_region(box, length):\n",
    "    \"\"\"\n",
    "    If confidence < 0.5, to obtain character bounding boxes\n",
    "    \"\"\"\n",
    "    if length == 1:\n",
    "        return [box]\n",
    "    \n",
    "    char_boxes = []\n",
    "    p1, p2, p3, p4 = box\n",
    "    if dist(p1, p2) + dist(p3, p4) > dist(p2, p3) + dist(p4, p1):\n",
    "        x_start1 = p1[0]\n",
    "        y_start1 = p1[1]\n",
    "        x_start2 = p4[0]\n",
    "        y_start2 = p4[1]\n",
    "        x_offset1 = (p2[0] - p1[0]) / length\n",
    "        y_offset1 = (p2[1] - p1[1]) / length\n",
    "        x_offset2 = (p3[0] - p4[0]) / length\n",
    "        y_offset2 = (p3[1] - p4[1]) / length\n",
    "    else:\n",
    "        x_offset1 = (p4[0] - p1[0]) / length\n",
    "        y_offset1 = (p4[1] - p1[1]) / length\n",
    "        x_offset2 = (p3[0] - p2[0]) / length\n",
    "        y_offset2 = (p3[1] - p2[1]) / length\n",
    "        x_start1 = p1[0]\n",
    "        y_start1 = p1[1]\n",
    "        x_start2 = p2[0]\n",
    "        y_start2 = p2[1]\n",
    "        \n",
    "    for i in range(length):\n",
    "        char_boxes.append([\n",
    "            [round(x_start1 + x_offset1 * i), round(y_start1 + y_offset1 * i)],\n",
    "            [round(x_start1 + x_offset1 * (i + 1)), round(y_start1 + y_offset1 * (i + 1))],\n",
    "            [round(x_start2 + x_offset2 * i), round(y_start2 + y_offset2 * i)],\n",
    "            [round(x_start2 + x_offset2 * (i + 1)), round(y_start2 + y_offset2 * (i + 1))]\n",
    "        ])\n",
    "\n",
    "    return char_boxes\n",
    "\n",
    "def enlarge_char_box(char_box, ratio):\n",
    "    x_center, y_center = np.average(char_box[:, 0]), np.average(char_box[:, 1])\n",
    "    char_box = char_box - [x_center, y_center]\n",
    "    char_box = char_box * ratio\n",
    "    char_box = char_box + [x_center, y_center]\n",
    "    return char_box\n",
    "\n",
    "\n",
    "def enlarge_char_boxes(char_boxes, crop_box):\n",
    "    char_boxes = np.reshape(np.array(char_boxes), newshape=(-1, 4, 2))\n",
    "    left, right, top, bottom = np.min(char_boxes[:, :, 0]), np.max(char_boxes[:, :, 0]), \\\n",
    "                               np.min(char_boxes[:, :, 1]), np.max(char_boxes[:, :, 1])\n",
    "    width, height = crop_box[2, 0], crop_box[2, 1]\n",
    "    offset = np.min([left, top, width - right, height - bottom])\n",
    "    ratio = 1 + offset * 2 / min(width, height)\n",
    "    char_boxes = np.array([enlarge_char_box(char_box, ratio) for char_box in char_boxes])\n",
    "    char_boxes[:, :, 0] = np.clip(char_boxes[:, :, 0], 0, width)\n",
    "    char_boxes[:, :, 1] = np.clip(char_boxes[:, :, 1], 0, height)\n",
    "    return char_boxes\n",
    "\n",
    "def conf(boxes, word):\n",
    "    box_count = len(boxes)\n",
    "    word_length = len(word)\n",
    "    confidence = (word_length - min(word_length, abs(word_length - box_count))) / word_length\n",
    "    return confidence\n",
    "\n",
    "def gen(src,word_boxes,words):\n",
    "    \"\"\"\n",
    "    src - Heat map generated from prediction\n",
    "    word_boxes - all box annotations for the src image\n",
    "    words - all texts in the src image\n",
    "    \n",
    "    Return:\n",
    "    char_boxes_list: boxes for characters in the original image space (not src image)\n",
    "    confidence_score: confidence mask for the given image - same size as src\n",
    "    \"\"\"\n",
    "    char_boxes_list = []\n",
    "    confidence_list = []\n",
    "    for word_box,word in zip(word_boxes, words):\n",
    "        img, src_points, crop_points = crop_image(src,word_box//2, dst_height=64.)\n",
    "        markers = watershed(img)\n",
    "        char_boxes = find_box(markers)\n",
    "        confidence = conf(char_boxes, word)\n",
    "        if confidence <= 0.5:\n",
    "            confidence = 0.5\n",
    "            char_boxes = divide_region(word_box, word_length)\n",
    "            char_boxes = [reorder_points(region_box) for region_box in region_boxes]\n",
    "        else:\n",
    "            char_boxes = np.array(region_boxes) * 2\n",
    "            char_boxes = enlarge_char_boxes(region_boxes, 2*crop_points)\n",
    "            char_boxes = [un_warping(region_box, 2*src_points, 2*crop_points) for region_box in region_boxes]\n",
    "            \n",
    "        char_boxes_list.append(char_boxes)\n",
    "        confidence_list.append(confidence)\n",
    "        \n",
    "    confidence_score = np.ones(src.shape[:2], dtype=np.float32)\n",
    "    for word_box, confidence_value in zip(word_boxes, confidence_list):\n",
    "        if confidence_value == 1:\n",
    "            continue\n",
    "        tmp_confidence_score = np.zeros(heat_map_size, dtype=np.uint8)\n",
    "        cv2.fillPoly(tmp_confidence_score, [np.array(word_box)], 1)\n",
    "        tmp_confidence_score = np.float32(tmp_confidence_score) * confidence_value\n",
    "        confidence_score = \\\n",
    "            np.where(tmp_confidence_score > confidence_score, tmp_confidence_score, confidence_score)\n",
    "        \n",
    "    return char_boxes_list, np.array(confidence_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
